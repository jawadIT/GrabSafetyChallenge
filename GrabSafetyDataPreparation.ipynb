{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries and set pyspark environment\n",
    "\n",
    "import sys,os,glob,math\n",
    "import pandas as pd\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"C:/Users/z001133/AppData/Local/Continuum/anaconda3/python.exe\"\n",
    "os.environ[\"SPARK_HOME\"] = \"D:/Public/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "spark = SparkSession.builder.appName(\"GrabChallengeSafety\").master(\"local[*]\").config('spark.executor.memory','20G').config('spark.driver.memory','10G').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "part-00001-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "part-00002-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "part-00003-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "part-00004-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "part-00005-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "part-00006-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "part-00007-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "part-00008-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n",
      "part-00009-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\n"
     ]
    }
   ],
   "source": [
    "#load features .csv files in to a dataframe\n",
    "os.chdir('C:\\\\Users\\\\z001133\\\\IdeaProjects\\\\pyLearning\\\\data\\\\features1')\n",
    "df_01 = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    print(file)\n",
    "    df_00 = pd.read_csv(file)\n",
    "    df_01 = df_01.append(df_00,ignore_index=True)\n",
    "    del df_00\n",
    "#df_02 = spark.createDataFrame(df_01[df_01['bookingID'] == 2])\n",
    "df_02 = spark.createDataFrame(df_01)\n",
    "del df_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_02 = spark.createDataFrame(df_01[df_01['bookingID'] == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_02.orderBy(\"second\").show(195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate magnitude of accelaration for the give accelaration x,y and z axis values\n",
    "from pyspark.sql.functions import udf\n",
    "def get_accelaration_magnitude(a,b,c):\n",
    "    p = (a*a + b*b + c*c)\n",
    "    return math.sqrt(p)\n",
    "get_accelaration_magnitude_udf = udf(get_accelaration_magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate degree of rotation in x,y, and z axis for the give gyrometer x,y and z values\n",
    "#create a new column speedT for temporary manipulation need down the line\n",
    "df_02 = df_02.withColumn(\"degreesX\",df_02[\"gyro_x\"]*57.2958) \\\n",
    ".withColumn(\"degreesY\",df_02[\"gyro_y\"]*57.2958) \\\n",
    ".withColumn(\"degreesZ\",df_02[\"gyro_z\"]*57.2958) \\\n",
    ".withColumn(\"acc_magn\",get_accelaration_magnitude_udf(df_02[\"acceleration_x\"],df_02[\"acceleration_y\"],df_02[\"acceleration_z\"])) \\\n",
    ".withColumn(\"speedT\",df_02[\"Speed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the columns needed\n",
    "df_02 = df_02.select(\"bookingID\",\"second\",\"Accuracy\",\"Bearing\",\"degreesZ\",\"acc_magn\",\"Speed\",\"speedT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group data by driving trip id , accuracy of gps , gps bearing position \n",
    "#this is to group the behaviour by change in the direction of drive\n",
    "#calculate average behaviour of degree of rotation, magnitude of accelaration, \n",
    "#total time taken in the direction, average speed and distance traveled in the direction\n",
    "\n",
    "df_02 = df_02.groupby(['bookingID','Accuracy','Bearing']) \\\n",
    "        .agg({\n",
    "        \"degreesZ\": \"mean\",\n",
    "        \"acc_magn\": \"mean\",\n",
    "        \"second\": \"max\",\n",
    "        \"Speed\": \"mean\",\n",
    "        \"speedT\": \"sum\"\n",
    "        }) \\\n",
    "    .withColumnRenamed(\"bookingID\",\"bkid\") \\\n",
    "    .withColumnRenamed(\"Bearing\",\"brng\") \\\n",
    "    .withColumnRenamed(\"Accuracy\",\"acrc\") \\\n",
    "    .withColumnRenamed(\"avg(degreesZ)\",\"degreesZ\") \\\n",
    "    .withColumnRenamed(\"avg(acc_magn)\",\"acc_magn\") \\\n",
    "    .withColumnRenamed(\"max(second)\",\"sub_total_time\") \\\n",
    "    .withColumnRenamed(\"avg(Speed)\",\"speed\") \\\n",
    "    .withColumnRenamed(\"sum(speedT)\",\"sub_total_distance\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_02.orderBy(\"timehr\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert time , speed and distance in to higher measures [hrs & km's]\n",
    "df_02 = df_02.withColumn(\"speedhr\",3.6*df_02['speed']) \\\n",
    "    .withColumn(\"timehr\",df_02['sub_total_time']/3600) \\\n",
    "    .withColumn(\"dist\",df_02['sub_total_distance']/1000)\n",
    "    \n",
    "df_02 = df_02.withColumn(\"timehrT\",df_02['timehr']) \\\n",
    "    .withColumn(\"distT\",df_02['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store data in to a temporary view\n",
    "df_02.createOrReplaceTempView('df_03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate difference of value for each direction change\n",
    "from pyspark.sql.functions import udf\n",
    "def check_first_row(a,b):\n",
    "    if b != 0:\n",
    "        return a-b\n",
    "    else:\n",
    "        return 0\n",
    "check_first_row_udf = udf(check_first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each change in direction calculate change in \n",
    "# bearing , accuracy, magnitude of accelaration, degree of rotation [taken z axis alone hoping it is aligned to the wheel]\n",
    "# distance , speed\n",
    "\n",
    "df_04 = spark.sql(\"\"\"select *,lag(brng,1,0) over (partition by bkid order by timehr) as prev_brng,\n",
    "     lag(acrc,1,0) over (partition by bkid order by timehr) as prev_acrc,\n",
    "     lag(acc_magn,1,0) over (partition by bkid order by timehr) as prev_acc_magn,\n",
    "     lag(degreesZ,1,0) over (partition by bkid order by timehr) as prev_degreesZ,\n",
    "     lag(dist,1,0) over (partition by bkid order by timehr) as prev_dist,\n",
    "     lag(speedhr,1,0) over (partition by bkid order by timehr) as prev_speed from df_03\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_04.orderBy(\"timehr\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the above define function calculate the delta values of above features\n",
    "\n",
    "df_04 = df_04.withColumn('delta_brng',check_first_row_udf(df_04['brng'],df_04['prev_brng']))\\\n",
    ".withColumn('delta_acrc',check_first_row_udf(df_04['acrc'],df_04['prev_acrc']))\\\n",
    ".withColumn('delta_acc_magn',check_first_row_udf(df_04['acc_magn'],df_04['prev_acc_magn']))\\\n",
    ".withColumn('delta_degreesZ',check_first_row_udf(df_04['degreesZ'],df_04['prev_degreesZ']))\\\n",
    ".withColumn('delta_dist',check_first_row_udf(df_04['dist'],df_04['prev_dist']))\\\n",
    ".withColumn('delta_speed',check_first_row_udf(df_04['speedhr'],df_04['prev_speed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_04.orderBy(\"timehr\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping data of each direction by drive trip id [booking id] to get the features that has the characteristics of a given driving\n",
    "#standard deviation in bearing (thats grouped earlier by direction change)\n",
    "#total number of direction changes\n",
    "#standard deviation in accuracy of gps\n",
    "#standard deviation in speed \n",
    "#standard deviation in acclearation magnitude\n",
    "#total time take for the trip\n",
    "#mean of the time across the direction changes\n",
    "#average distance across the direction changes\n",
    "#total distance travelled for the trip\n",
    "#standard deviation of the changes that happened between the direction changes \n",
    "#accuracy,magnitude of accelaration,degree of rotatio,distance & speed\n",
    "\n",
    "df_05 = df_04.groupBy('bkid') \\\n",
    "        .agg({\n",
    "        \"brng\": \"std\",\n",
    "        \"bkid\": \"count\",\n",
    "        \"acrc\": \"std\",\n",
    "        \"degreesZ\": \"std\",\n",
    "        \"speedhr\": \"std\",\n",
    "        \"acc_magn\": \"std\",\n",
    "        \"timehr\": \"max\",\n",
    "        \"timehrT\": \"mean\",\n",
    "        \"dist\": \"mean\",\n",
    "        \"distT\": \"sum\",\n",
    "        \"delta_brng\": \"std\",\n",
    "        \"delta_acrc\": \"std\",\n",
    "        \"delta_acc_magn\": \"std\",\n",
    "        \"delta_degreesZ\": \"std\",\n",
    "        \"delta_dist\": \"std\",\n",
    "        \"delta_speed\": \"std\"\n",
    "    }) \\\n",
    "        .withColumnRenamed(\"bkid\",\"bookID\") \\\n",
    "        .withColumnRenamed(\"stddev(brng)\",\"bearing\") \\\n",
    "        .withColumnRenamed(\"count(bkid)\",\"no_of_turns\") \\\n",
    "        .withColumnRenamed(\"stddev(acrc)\",\"accuracy\") \\\n",
    "        .withColumnRenamed(\"stddev(degreesZ)\",\"degreesZ\") \\\n",
    "        .withColumnRenamed(\"stddev(acc_magn)\",\"acc_magn\") \\\n",
    "        .withColumnRenamed(\"avg(timehrT)\",\"time_per_turn\") \\\n",
    "        .withColumnRenamed(\"max(timehr)\",\"total_time\") \\\n",
    "        .withColumnRenamed(\"stddev(speedhr)\",\"speed\") \\\n",
    "        .withColumnRenamed(\"avg(dist)\",\"distance_per_turn\") \\\n",
    "        .withColumnRenamed(\"sum(distT)\",\"total_ditance\") \\\n",
    "        .withColumnRenamed(\"stddev(delta_brng)\",\"change_in_bearing\") \\\n",
    "        .withColumnRenamed(\"stddev(delta_acrc)\",\"change_in_accuracy\") \\\n",
    "        .withColumnRenamed(\"stddev(delta_acc_magn)\",\"change_in_accelaration\") \\\n",
    "        .withColumnRenamed(\"stddev(delta_degreesZ)\",\"change_in_gyro\") \\\n",
    "        .withColumnRenamed(\"stddev(delta_dist)\",\"change_in_dist\") \\\n",
    "        .withColumnRenamed(\"stddev(delta_speed)\",\"change_in_speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_05.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_05.coalesce(1).write.option(\"header\",\"true\").csv(\"C:\\\\Users\\\\z001133\\\\IdeaProjects\\\\pyLearning\\\\data\\\\features\\\\features_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-e9445087-aa0a-433b-a7f6-7f4c19d78ad6-c000.csv\n",
      "Row(bookingID=111669149733, label=0)\n"
     ]
    }
   ],
   "source": [
    "#read the label values in to a dataframe\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\z001133\\\\IdeaProjects\\\\pyLearning\\\\data\\\\labels')\n",
    "df_01 = pd.DataFrame()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    print(file)\n",
    "    df_00 = pd.read_csv(file)\n",
    "    df_01 = df_01.append(df_00,ignore_index=True)\n",
    "    del df_00\n",
    "df_02 = spark.createDataFrame(df_01)\n",
    "del df_01\n",
    "print(df_02.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the features and labels\n",
    "df_06 = df_05.join(df_02, df_05[\"bookID\"] == df_02[\"bookingID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the data at trip level (1 observation per trip) in a .csv file\n",
    "\n",
    "df_06.coalesce(1).write.option(\"header\",\"true\").csv(\"C:\\\\Users\\\\z001133\\\\IdeaProjects\\\\pyLearning\\\\data\\\\labels\\\\consolidated.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
